{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573c2ded",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation - PDF Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee41776",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "- Creating Vector Embeddings\n",
    "- Indexing PDF\n",
    "- Storing Vectors in Database (Chroma)\n",
    "- Querying PDF\n",
    "- Using Langchain for Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90228ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.3.25)\n",
      "Requirement already satisfied: chromadb in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.0.10)\n",
      "Requirement already satisfied: pypdf in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (5.5.0)\n",
      "Requirement already satisfied: pytest in ./venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (8.3.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.3.61)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: build>=1.0.3 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.2.2.post1)\n",
      "Requirement already satisfied: fastapi==0.115.9 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.115.9)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.34.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.33.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 2)) (4.24.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in ./venv/lib/python3.11/site-packages (from fastapi==0.115.9->chromadb->-r requirements.txt (line 2)) (0.45.3)\n",
      "Requirement already satisfied: iniconfig in ./venv/lib/python3.11/site-packages (from pytest->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from pytest->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./venv/lib/python3.11/site-packages (from pytest->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 2)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 2)) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.40.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.10)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (5.29.4)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in ./venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in ./venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.33.1 in ./venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 2)) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in ./venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in ./venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in ./venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.54b1 in ./venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (0.54b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb->-r requirements.txt (line 2)) (0.32.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 2)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (4.9.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 2)) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 2)) (3.22.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 2)) (0.6.1)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9b7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(\"data\")\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096f7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc82a948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1'}, page_content='Convolutional Neural Network: A Quick Overview \\nIn the world of AI, Machine Learning, Deep Learning, and Computer Vision, we have come \\nacross and heard about various tasks like Image Classification, Object Detection, Image Pattern \\nDetection, Text Classification, and Face Recognition. In this article, I have written a quick \\noverview of Convolutional Neural Networks. \\nConvolutional Neural Network (CNN or ConvNets) is a Deep Learning technique which is \\ngenerally used to perform the tasks mentioned above. Here, the input is an image (simply a \\nmatrix of pixels) which is fed into a CNN model that assigns some learnable weights and biases \\nto various aspects of an image to analyze input images for recognition and classification. Just \\nlike teachers help toddlers recognize different letters and digits through images and diagrams, \\nsimilarly, computers are also trained on large datasets (millions and thousands of images) for \\nimage or text recognition tasks. \\n \\n \\nA (28 x 28 x 1) pi xel grayscale image from the EMNIST \\ndataset for character Z. This is fed as input to a CNN model \\nwhich then predicts its label based on the learning and \\nfeatures. \\n \\n \\nThe elementary role of a CNN model is to modify the images into a form that is computationally \\nless expensive  with no  loss of  features, which  are important for getting good and accurate \\npredictions.  \\nTypes of Layers in a CNN model: \\n1. Convolutional Layer \\n2. Pooling Layer \\n3. Fully Connected (Dense Layer) \\n \\n1. Convolutional Layer: In the Convolution al Layer, the convolution operation is performed to \\nget the position and strength of features of the input image. It takes an input image (say 12 x 12 \\nimage) and convolves (dot product) with a filter (say 3 x 3 filter/kernel) to give a convolved image \\nof size 10 x 10 (if p=0 i.e. valid padding and s = 1).  \\n \\n([n + 2p – f]/s+ 1) x ([n + 2p – f]/s+ 1) is the dimension of convolved image after convolution  \\noperation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2'}, page_content='Note:  n = Input image dimensions \\n            p = padding \\n            f = size of filter \\n            s = stride \\n \\n \\nPadding: Padding is a hyperparameter of a Convolutional Layer. It is a process of adding zeros to \\nour input images. If we use the convolutional layer without setting the padding parameter, then \\nthe output image shrinks and there are chances of information/features from edges getting lost.  \\n \\n           Types of Padding  \\n \\nSame Padding \\nPadding so the output image has the \\nsame size as the input image. \\np = (f – 1) / 2 \\n        (n + 2p) x (n + 2p) * (f x f) => (n x n)  \\n \\nValid Padding \\nNo Padding. The output image shrinks \\ndepending on input & filter size. \\np = 0 \\n    (n x n) * (f x f) => (n – f + 1) x (n – f + 1)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3'}, page_content='Note:  * is a convolution operation \\nA Quick Note: Filter/kernel is a matrix of size (f x f) and f – a hyperparameter, is usually odd like 3 \\nx 3, 5 x 5, 7 x 7, etc. \\nNo. of channels of Filter = No of channels of image. \\nStrides: Strides is another hyperparameter in the convolution layer which tells about the number \\nof pixels to shift the filter over the input matrix. If we set s = 3, shifting filter over input image by \\n3 pixels. \\n \\n2. Pooling Layer: Usually used after a Convolution al Layer. The pooling layer is responsible for \\nreducing the size of the Convolved Feature s. In this layer, there are no parameters and weights \\nto learn for the model. It aims to reduce the size of the representation to speed up the \\ncomputation and to make some features more robust i.e. extracting dominant features  from \\nconvolved images.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4'}, page_content='Max Pooling \\n  \\n          \\n        4 x 4 Image \\n \\n \\n        Average Pooling  \\n \\n \\n \\n         4 x 4 Image \\nA Quick Note: Feature Maps in CNN captures features which is the output of applying filters to \\nthe input image.  \\n \\n3. Fully Connected (Dense): A Fully Connected Layer (Dense Layer) takes the output of the \\nprevious layers (usually Pooling Layers) and flattens it to a single vector. The 1st fully connected \\nlayer takes in the features and assigns weights to them, and the output Dense Layer gives the \\nprobabilities for each class using an activation function. \\n \\nA general strategy for creating a CNN Model:- \\n1. Input an image into the convolutional layer. Select appropriate parameters (filters, \\nstrides, and padding). Perform convolution on the image and use an activation function \\ndepending on the task to be performed. \\n2. Add a Pooling Layer and perform pooling to reduce dimensionality size. Max or Avg \\nPooling can be used based on functionality. \\n3. Add convolutional layers to the model as per accuracy/loss i.e. the metric chosen and \\ndepth of Neural Network required based on image complexity. \\n1 3 2 1 \\n2 9 1 1 \\n  1 3 2 3 \\n  5 6 1 2 \\n9 2 \\n6 3 \\n1 3 2 1 \\n2 9 1 1 \\n  1 4 2 3 \\n  5 6 1 2 \\n3.75 1.25 \\n  4 2 \\n2 x 2 Feature map \\n2 x 2 Feature Map'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5'}, page_content='4. Flatten the output (Flatten Layer) and feed into a fully connected dense layer (FC Layer). \\n5. Output the classes using an activation function using Dense Layer. Additionally, we can \\nuse Batch Normalization and Dropout Layers to improve the performance of our model. \\n \\nLet’s take an example to understand the dimensions  of images at each layer of a CNN \\nmodel . Let’s take a simple CNN model as shown below:  \\n \\n     Basic CNN Architecture  \\n \\nThe input is (32 x 32 x 3) dimensional image which is fed into a Convolutional Layer .  \\n \\nIn 1st Convolutional Layer , f = 5  -> a filter matrix of size (5 x 5) that’s convolved with (32 x 32 x \\n3) image with same padding and s = 1 to get a (32 x 32 x n) dimensional image. Let’s assume there \\nare n filters of size (5 x 5). Hence, dimension of image is (32, 32, n). \\nCalculation:      p = (f-1)/2 = (5-1)/2 = 2 \\n   ([n + 2p – f]/s + 1) = ([32 + 2(2) – 5]/1 + 1) = 32      \\nUsing p = same, after calculations we are getting an output image of the same size as the input \\nimage.  \\nIn Pooling Layer 1, we get a matrix with features having either maximum or average value. For \\n(32 x 32 x n) convolved image with a stride of s = 2 and pool size = 2, we get a (16 x 16 x n) image. \\n \\nIn 2nd Convolutional Layer , f = 3 -> a filter matrix of size (3 x 3) that’s convolved with (16 x 16 \\nx n) image with valid padding to get a ( 14 x 14) dimensional image. Here, s = 1 , and the filter \\nmoves by 1 pixel. Let’s assume there are n’ filters of size (3 x 3). Hence dimension of the convolved \\nimage is (14, 14, n’). \\nCalculation:      p = 0'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6'}, page_content='([n + 2p – f]/s + 1) = ([16 + 2(0) – 3]/1 + 1) = 14 \\n \\nIn Pooling Layer 2, either a maximum pool or an average pool can be used. For (14 x 14 x n’) \\nconvolved image we get a (7 x 7 x n’) image since we have used a stride of s = 2 and pool size = 2. \\n \\nThis image is then fed to the Flatten Layer to convert the 3D image into a 1D vector of size 7 * 7 \\n* n` = 49*n`. This is then fed into Dense Layer having x units/neurons with some normalization \\ntechniques/layers to improve the model’s performance. Another Output Dense Layer with y \\nclasses (depending on the problem being considered) outputs labels or probabilities. \\n \\nHow do we calculate no. of parameters for a Convolutional Layer and Fully Connected Layer? \\n# Parameters in Conv. Layer : [ (f x f x no. of channels in previous layer)+ 1] x no. of filters \\n# Parameters in FC Layer : [no. of units in current layer x no of units in previous layer] + no. of \\nunits in current layer \\nNote: There are no parameters for Pooling Layer because it’s used to reduce the dimensionality \\nof the image and has no learning of parameters while training the model. \\n \\n \\nLet’s take an example to calculate no. of parameters for a Convolutional Layer and FC Layer: \\nNo. of parameters in Convolutional Layer 1 of ‘Basic CNN Architecture’ figure :- \\nHere, f = 5, no. of filters = n = 64(say) and no. of channels in previous layer = 3 \\nTherefore, [(5 x 5 x 3) +1] x 64 = 4864 no. of parameters \\nNo. of parameters in Fully Connected Layer (Dense Layer) of ‘Basic CNN Architecture’ figure \\n:- \\nHere, no. of units in current layer = 120 (say) and no. of units in previous layer = 400 (say)   \\nTherefore, [120 x 400] + 64 = 48064 no. of parameters'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 6, 'page_label': '7'}, page_content=''),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='Neural Networks: A Quick Overview  \\n \\nNeural Networks are indispensable for Deep Learning. The basic idea behind Neural Networks is \\nthe Perceptron Model which is similar to biological neuron s in terms of both features and \\nfunctionality. Neural networks are the network of artificial neurons or nodes that learns features \\nand patterns from input data by analyzing and performing computational tasks to give the \\ndesired output after training on the dataset. \\n \\n \\nA Perceptron Model \\nWeights – Weights are associated with every input neuron. They are the information used by \\nneurons and represent the strength of the connection between neurons in a Neural Network. \\nThe more the weight of the neuron, the more impact it will have. Dimensions: w[l] → (n[l],n[l-\\n1]) \\nBias – Bias allows the activation function to shift by a constant value. It’s used to adjust the \\noutput of the weighted sum of input. It’s analogous to an intercept of a linear equation. \\nDimensions: b[l] → (n[l],1) \\nNote: n[l] - no of nodes/neurons in the lth layer. n[l-1] – no of nodes/neurons in the previous \\nlayer i.e. (l-1)th layer.   \\nThree Major Types of Neural Networks: \\n1. Artificial Neural Network (ANN) – Voice recognition,  \\n2. Convolutional Neural Network (CNN)  – Image Recognition, image classification, face \\nrecognition, object detection, pattern recognition, etc.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='3. Recurrent Neural Network (RNN)  – Speech Recognition, Machine Translation, Music \\ngeneration, Sentiment Classification, Name entity recognition, etc.  \\n \\n \\nLet’s see a brief overview of ANNs in this section. \\nIn a complete Neural Network i.e. a multi-layer perceptron model, every neuron is connected to \\nevery neuron in the next layer. Also called Fully Connected Dense Layer. Artificial Neural Nets can \\nbe visualized as directed weighted graphs where each neuron is a node and an edge represents \\nweights between input and output neurons. \\n3 Types of Layers:  \\n1. Input Layer – Input Feature Matrix (x1,x2,…xm) of size (nx, nm) \\n2. Hidden Layers  – Processing the input  and performing all the computations to find \\nhidden patterns and features. \\n3. Output Layer – Outputs the learning (y1,y2,…ym) of size (1, m) \\nNote: m is the no. of training data/examples. \\nThere can be multiple hidden layers depending on the problem’s complexity and functionality.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content='In an Artificial Neural Network (ANN), there are 2 elementary steps of computation for each \\nneuron as shown below: \\nStep 1: z = ∑ (wTx + b) \\nStep 2 : a = σ(z). Here, σ is an activation function. \\n \\n \\nNote: Here, w and b are parameters. \\nThe idea is that each layer learns weights during the training of the data and the learned data is \\nthen fed to an activation function to get the output. The no. of layers and no. of neurons or \\nnodes (hyperparameters) in each hidden layer depends on the complexity of the problem and \\nshould be tuned to get the desired result. There is a bi-directional propagation i.e. Forward \\nPropagation and Backward Propagation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='Few terminologies: \\n1. Activation Function – It’s a function that defines the output of a neuron and determines \\nwhether a neuron should be activated or not. \\nTypes of Activation Functions: \\n \\nNote: ReLu → Rectified Linear Unit'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='1. Loss Function – The Loss function is used to evaluate the performance of the model. It \\ndefines the measure of how good output y^ performs when the true label is y. \\n \\n2. Cost Function – It measures how well parameters w and b are doing on the training set. \\nCost Function : J(w , b) = 1/m * ( ∑ L(y^ , y) ) \\nNote: Initialization of w and b should never be zero. It should be initialized to random numbers. \\nPoor initialization leads to vanishing or exploding gradients which decelerates the optimization \\nalgorithms. \\nIn forward Propagation, weights are multiplied with inputs and biases are added which is then \\nfed to an activation function (as shown in the diagram). The model learns by adjusting weights \\nand biases (parameters) using algorithms. \\n \\nIn backpropagation, gradient of the loss function is computed. Algorithms iterate backward by \\ncomputing the partial derivative of cost function w.r.t all parameters. \\nNote: Gradient Descent is performed to minimize the cost or loss function. Gradient Descent is \\nthe most common optimization Algorithm used in Deep Learning. Other Optimization \\nAlgorithms are Adam, Gradient Descent with Momentum, mini-batch Gradient Descent, and \\nRoot Mean Square prop (RMSprop).  \\nGeneral Method to build a Neural Network: \\n1. Define the Neural Network Structure according to the problem under consideration – \\nno. of input neurons, hidden nodes, no. of layers, learning rate α, etc. \\n2. Initialize parameters - weights and biases. \\n3. Iterate –  No of iterations depends on batch size and no. of batches (hyperparameters) \\n1. Perform Forward Prop – In forward pass, model generates its initial predictions \\n z[l] = w[l] a[l-1] + b[l] \\na[l] = g[l](z[l]) \\n2. Compute Loss – Loss function is calculated to check how far the actual and predicted \\nvalue are. \\n3. Implement Backward Propogation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content='dz[l] = a[l] – y \\ndw[l] = 1/m * (dz[l]* a[l-1].T ) \\ndb[l] = 1/m * np.sum(dz[l], keepdims = true, axis =1)  //Note: keepdims helps to \\nprevent rank 1 arrays  \\n………. \\ndz[l-1] = w[l].T * dz[l] * g’[l-1](z[l-1]) \\n4. Update parameters \\nW[l] = w[l] – α*dw[l] \\nb[l] = b[l] – α*db[l] \\n \\nNote: 1 epoch is one iteration of the entire training set. Batch size is the total no of training \\nexamples in a single batch. Iterations is no of batches of the batch size needed to complete 1 \\nepoch. \\nLet’s take an example:  \\nm = 10,000 training examples. \\nSay, we have a batch size of 1000. So, to complete 1 epoch i.e. to cover all 10,000 examples \\nwe would require 100 no of batches or iterations.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 6, 'page_label': '7'}, page_content='Notations: \\nLayer l : w[l], b[l] \\nForward Prop: Input – a[l-1] and Output – a[l] \\nZ[l] = w[l]a[l-1] + b[l] \\na[l] = g[l](z[l]) \\nNote: da[l] is calculated after applying loss function \\nBackward Prop: Input- da[l], z[l] and  output – da[l-1], dw[l],db[l]  \\nHyperparameters:  \\n1. Learning Rate – α \\n2. No of iterations of gradient descent/ optimization algorithm \\n3. No of hidden layers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 7, 'page_label': '8'}, page_content='4. No of neurons in each layer \\n5. Activation function choice \\nApplications and Scope of Neural Networks: Neural Networks finds application from industry to \\nday-to-day tasks like image recognition, speech to text, machine translation, signature \\nverification, object detection, and many more.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aece3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "\n",
    "# Split the document into smaller chunks using LangChain's Recursive Character Text Splitter\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c3c7b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1'}, page_content='Convolutional Neural Network: A Quick Overview \\nIn the world of AI, Machine Learning, Deep Learning, and Computer Vision, we have come \\nacross and heard about various tasks like Image Classification, Object Detection, Image Pattern \\nDetection, Text Classification, and Face Recognition. In this article, I have written a quick \\noverview of Convolutional Neural Networks. \\nConvolutional Neural Network (CNN or ConvNets) is a Deep Learning technique which is \\ngenerally used to perform the tasks mentioned above. Here, the input is an image (simply a \\nmatrix of pixels) which is fed into a CNN model that assigns some learnable weights and biases \\nto various aspects of an image to analyze input images for recognition and classification. Just'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1'}, page_content='like teachers help toddlers recognize different letters and digits through images and diagrams, \\nsimilarly, computers are also trained on large datasets (millions and thousands of images) for \\nimage or text recognition tasks. \\n \\n \\nA (28 x 28 x 1) pi xel grayscale image from the EMNIST \\ndataset for character Z. This is fed as input to a CNN model \\nwhich then predicts its label based on the learning and \\nfeatures. \\n \\n \\nThe elementary role of a CNN model is to modify the images into a form that is computationally \\nless expensive  with no  loss of  features, which  are important for getting good and accurate \\npredictions.  \\nTypes of Layers in a CNN model: \\n1. Convolutional Layer \\n2. Pooling Layer \\n3. Fully Connected (Dense Layer)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 0, 'page_label': '1'}, page_content='1. Convolutional Layer \\n2. Pooling Layer \\n3. Fully Connected (Dense Layer) \\n \\n1. Convolutional Layer: In the Convolution al Layer, the convolution operation is performed to \\nget the position and strength of features of the input image. It takes an input image (say 12 x 12 \\nimage) and convolves (dot product) with a filter (say 3 x 3 filter/kernel) to give a convolved image \\nof size 10 x 10 (if p=0 i.e. valid padding and s = 1).  \\n \\n([n + 2p – f]/s+ 1) x ([n + 2p – f]/s+ 1) is the dimension of convolved image after convolution  \\noperation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 1, 'page_label': '2'}, page_content='Note:  n = Input image dimensions \\n            p = padding \\n            f = size of filter \\n            s = stride \\n \\n \\nPadding: Padding is a hyperparameter of a Convolutional Layer. It is a process of adding zeros to \\nour input images. If we use the convolutional layer without setting the padding parameter, then \\nthe output image shrinks and there are chances of information/features from edges getting lost.  \\n \\n           Types of Padding  \\n \\nSame Padding \\nPadding so the output image has the \\nsame size as the input image. \\np = (f – 1) / 2 \\n        (n + 2p) x (n + 2p) * (f x f) => (n x n)  \\n \\nValid Padding \\nNo Padding. The output image shrinks \\ndepending on input & filter size. \\np = 0 \\n    (n x n) * (f x f) => (n – f + 1) x (n – f + 1)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3'}, page_content='Note:  * is a convolution operation \\nA Quick Note: Filter/kernel is a matrix of size (f x f) and f – a hyperparameter, is usually odd like 3 \\nx 3, 5 x 5, 7 x 7, etc. \\nNo. of channels of Filter = No of channels of image. \\nStrides: Strides is another hyperparameter in the convolution layer which tells about the number \\nof pixels to shift the filter over the input matrix. If we set s = 3, shifting filter over input image by \\n3 pixels. \\n \\n2. Pooling Layer: Usually used after a Convolution al Layer. The pooling layer is responsible for \\nreducing the size of the Convolved Feature s. In this layer, there are no parameters and weights \\nto learn for the model. It aims to reduce the size of the representation to speed up the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3'}, page_content='computation and to make some features more robust i.e. extracting dominant features  from \\nconvolved images.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4'}, page_content='Max Pooling \\n  \\n          \\n        4 x 4 Image \\n \\n \\n        Average Pooling  \\n \\n \\n \\n         4 x 4 Image \\nA Quick Note: Feature Maps in CNN captures features which is the output of applying filters to \\nthe input image.  \\n \\n3. Fully Connected (Dense): A Fully Connected Layer (Dense Layer) takes the output of the \\nprevious layers (usually Pooling Layers) and flattens it to a single vector. The 1st fully connected \\nlayer takes in the features and assigns weights to them, and the output Dense Layer gives the \\nprobabilities for each class using an activation function. \\n \\nA general strategy for creating a CNN Model:- \\n1. Input an image into the convolutional layer. Select appropriate parameters (filters, \\nstrides, and padding). Perform convolution on the image and use an activation function'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4'}, page_content='depending on the task to be performed. \\n2. Add a Pooling Layer and perform pooling to reduce dimensionality size. Max or Avg \\nPooling can be used based on functionality. \\n3. Add convolutional layers to the model as per accuracy/loss i.e. the metric chosen and \\ndepth of Neural Network required based on image complexity. \\n1 3 2 1 \\n2 9 1 1 \\n  1 3 2 3 \\n  5 6 1 2 \\n9 2 \\n6 3 \\n1 3 2 1 \\n2 9 1 1 \\n  1 4 2 3 \\n  5 6 1 2 \\n3.75 1.25 \\n  4 2 \\n2 x 2 Feature map \\n2 x 2 Feature Map'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5'}, page_content='4. Flatten the output (Flatten Layer) and feed into a fully connected dense layer (FC Layer). \\n5. Output the classes using an activation function using Dense Layer. Additionally, we can \\nuse Batch Normalization and Dropout Layers to improve the performance of our model. \\n \\nLet’s take an example to understand the dimensions  of images at each layer of a CNN \\nmodel . Let’s take a simple CNN model as shown below:  \\n \\n     Basic CNN Architecture  \\n \\nThe input is (32 x 32 x 3) dimensional image which is fed into a Convolutional Layer .  \\n \\nIn 1st Convolutional Layer , f = 5  -> a filter matrix of size (5 x 5) that’s convolved with (32 x 32 x \\n3) image with same padding and s = 1 to get a (32 x 32 x n) dimensional image. Let’s assume there'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5'}, page_content='are n filters of size (5 x 5). Hence, dimension of image is (32, 32, n). \\nCalculation:      p = (f-1)/2 = (5-1)/2 = 2 \\n   ([n + 2p – f]/s + 1) = ([32 + 2(2) – 5]/1 + 1) = 32      \\nUsing p = same, after calculations we are getting an output image of the same size as the input \\nimage.  \\nIn Pooling Layer 1, we get a matrix with features having either maximum or average value. For \\n(32 x 32 x n) convolved image with a stride of s = 2 and pool size = 2, we get a (16 x 16 x n) image. \\n \\nIn 2nd Convolutional Layer , f = 3 -> a filter matrix of size (3 x 3) that’s convolved with (16 x 16 \\nx n) image with valid padding to get a ( 14 x 14) dimensional image. Here, s = 1 , and the filter \\nmoves by 1 pixel. Let’s assume there are n’ filters of size (3 x 3). Hence dimension of the convolved'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 4, 'page_label': '5'}, page_content='image is (14, 14, n’). \\nCalculation:      p = 0'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6'}, page_content='([n + 2p – f]/s + 1) = ([16 + 2(0) – 3]/1 + 1) = 14 \\n \\nIn Pooling Layer 2, either a maximum pool or an average pool can be used. For (14 x 14 x n’) \\nconvolved image we get a (7 x 7 x n’) image since we have used a stride of s = 2 and pool size = 2. \\n \\nThis image is then fed to the Flatten Layer to convert the 3D image into a 1D vector of size 7 * 7 \\n* n` = 49*n`. This is then fed into Dense Layer having x units/neurons with some normalization \\ntechniques/layers to improve the model’s performance. Another Output Dense Layer with y \\nclasses (depending on the problem being considered) outputs labels or probabilities. \\n \\nHow do we calculate no. of parameters for a Convolutional Layer and Fully Connected Layer?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6'}, page_content='# Parameters in Conv. Layer : [ (f x f x no. of channels in previous layer)+ 1] x no. of filters \\n# Parameters in FC Layer : [no. of units in current layer x no of units in previous layer] + no. of \\nunits in current layer \\nNote: There are no parameters for Pooling Layer because it’s used to reduce the dimensionality \\nof the image and has no learning of parameters while training the model. \\n \\n \\nLet’s take an example to calculate no. of parameters for a Convolutional Layer and FC Layer: \\nNo. of parameters in Convolutional Layer 1 of ‘Basic CNN Architecture’ figure :- \\nHere, f = 5, no. of filters = n = 64(say) and no. of channels in previous layer = 3 \\nTherefore, [(5 x 5 x 3) +1] x 64 = 4864 no. of parameters'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:25+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:25+00:00', 'source': 'data/CNN.pdf', 'total_pages': 7, 'page': 5, 'page_label': '6'}, page_content='Therefore, [(5 x 5 x 3) +1] x 64 = 4864 no. of parameters \\nNo. of parameters in Fully Connected Layer (Dense Layer) of ‘Basic CNN Architecture’ figure \\n:- \\nHere, no. of units in current layer = 120 (say) and no. of units in previous layer = 400 (say)   \\nTherefore, [120 x 400] + 64 = 48064 no. of parameters'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='Neural Networks: A Quick Overview  \\n \\nNeural Networks are indispensable for Deep Learning. The basic idea behind Neural Networks is \\nthe Perceptron Model which is similar to biological neuron s in terms of both features and \\nfunctionality. Neural networks are the network of artificial neurons or nodes that learns features \\nand patterns from input data by analyzing and performing computational tasks to give the \\ndesired output after training on the dataset. \\n \\n \\nA Perceptron Model \\nWeights – Weights are associated with every input neuron. They are the information used by \\nneurons and represent the strength of the connection between neurons in a Neural Network. \\nThe more the weight of the neuron, the more impact it will have. Dimensions: w[l] → (n[l],n[l-\\n1])'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 0, 'page_label': '1'}, page_content='1]) \\nBias – Bias allows the activation function to shift by a constant value. It’s used to adjust the \\noutput of the weighted sum of input. It’s analogous to an intercept of a linear equation. \\nDimensions: b[l] → (n[l],1) \\nNote: n[l] - no of nodes/neurons in the lth layer. n[l-1] – no of nodes/neurons in the previous \\nlayer i.e. (l-1)th layer.   \\nThree Major Types of Neural Networks: \\n1. Artificial Neural Network (ANN) – Voice recognition,  \\n2. Convolutional Neural Network (CNN)  – Image Recognition, image classification, face \\nrecognition, object detection, pattern recognition, etc.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='3. Recurrent Neural Network (RNN)  – Speech Recognition, Machine Translation, Music \\ngeneration, Sentiment Classification, Name entity recognition, etc.  \\n \\n \\nLet’s see a brief overview of ANNs in this section. \\nIn a complete Neural Network i.e. a multi-layer perceptron model, every neuron is connected to \\nevery neuron in the next layer. Also called Fully Connected Dense Layer. Artificial Neural Nets can \\nbe visualized as directed weighted graphs where each neuron is a node and an edge represents \\nweights between input and output neurons. \\n3 Types of Layers:  \\n1. Input Layer – Input Feature Matrix (x1,x2,…xm) of size (nx, nm) \\n2. Hidden Layers  – Processing the input  and performing all the computations to find \\nhidden patterns and features.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 1, 'page_label': '2'}, page_content='hidden patterns and features. \\n3. Output Layer – Outputs the learning (y1,y2,…ym) of size (1, m) \\nNote: m is the no. of training data/examples. \\nThere can be multiple hidden layers depending on the problem’s complexity and functionality.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 2, 'page_label': '3'}, page_content='In an Artificial Neural Network (ANN), there are 2 elementary steps of computation for each \\nneuron as shown below: \\nStep 1: z = ∑ (wTx + b) \\nStep 2 : a = σ(z). Here, σ is an activation function. \\n \\n \\nNote: Here, w and b are parameters. \\nThe idea is that each layer learns weights during the training of the data and the learned data is \\nthen fed to an activation function to get the output. The no. of layers and no. of neurons or \\nnodes (hyperparameters) in each hidden layer depends on the complexity of the problem and \\nshould be tuned to get the desired result. There is a bi-directional propagation i.e. Forward \\nPropagation and Backward Propagation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 3, 'page_label': '4'}, page_content='Few terminologies: \\n1. Activation Function – It’s a function that defines the output of a neuron and determines \\nwhether a neuron should be activated or not. \\nTypes of Activation Functions: \\n \\nNote: ReLu → Rectified Linear Unit'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='1. Loss Function – The Loss function is used to evaluate the performance of the model. It \\ndefines the measure of how good output y^ performs when the true label is y. \\n \\n2. Cost Function – It measures how well parameters w and b are doing on the training set. \\nCost Function : J(w , b) = 1/m * ( ∑ L(y^ , y) ) \\nNote: Initialization of w and b should never be zero. It should be initialized to random numbers. \\nPoor initialization leads to vanishing or exploding gradients which decelerates the optimization \\nalgorithms. \\nIn forward Propagation, weights are multiplied with inputs and biases are added which is then \\nfed to an activation function (as shown in the diagram). The model learns by adjusting weights \\nand biases (parameters) using algorithms.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='and biases (parameters) using algorithms. \\n \\nIn backpropagation, gradient of the loss function is computed. Algorithms iterate backward by \\ncomputing the partial derivative of cost function w.r.t all parameters. \\nNote: Gradient Descent is performed to minimize the cost or loss function. Gradient Descent is \\nthe most common optimization Algorithm used in Deep Learning. Other Optimization \\nAlgorithms are Adam, Gradient Descent with Momentum, mini-batch Gradient Descent, and \\nRoot Mean Square prop (RMSprop).  \\nGeneral Method to build a Neural Network: \\n1. Define the Neural Network Structure according to the problem under consideration – \\nno. of input neurons, hidden nodes, no. of layers, learning rate α, etc. \\n2. Initialize parameters - weights and biases.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 4, 'page_label': '5'}, page_content='2. Initialize parameters - weights and biases. \\n3. Iterate –  No of iterations depends on batch size and no. of batches (hyperparameters) \\n1. Perform Forward Prop – In forward pass, model generates its initial predictions \\n z[l] = w[l] a[l-1] + b[l] \\na[l] = g[l](z[l]) \\n2. Compute Loss – Loss function is calculated to check how far the actual and predicted \\nvalue are. \\n3. Implement Backward Propogation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 5, 'page_label': '6'}, page_content='dz[l] = a[l] – y \\ndw[l] = 1/m * (dz[l]* a[l-1].T ) \\ndb[l] = 1/m * np.sum(dz[l], keepdims = true, axis =1)  //Note: keepdims helps to \\nprevent rank 1 arrays  \\n………. \\ndz[l-1] = w[l].T * dz[l] * g’[l-1](z[l-1]) \\n4. Update parameters \\nW[l] = w[l] – α*dw[l] \\nb[l] = b[l] – α*db[l] \\n \\nNote: 1 epoch is one iteration of the entire training set. Batch size is the total no of training \\nexamples in a single batch. Iterations is no of batches of the batch size needed to complete 1 \\nepoch. \\nLet’s take an example:  \\nm = 10,000 training examples. \\nSay, we have a batch size of 1000. So, to complete 1 epoch i.e. to cover all 10,000 examples \\nwe would require 100 no of batches or iterations.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 6, 'page_label': '7'}, page_content='Notations: \\nLayer l : w[l], b[l] \\nForward Prop: Input – a[l-1] and Output – a[l] \\nZ[l] = w[l]a[l-1] + b[l] \\na[l] = g[l](z[l]) \\nNote: da[l] is calculated after applying loss function \\nBackward Prop: Input- da[l], z[l] and  output – da[l-1], dw[l],db[l]  \\nHyperparameters:  \\n1. Learning Rate – α \\n2. No of iterations of gradient descent/ optimization algorithm \\n3. No of hidden layers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2025-05-27T07:13:56+00:00', 'author': 'Anaya', 'moddate': '2025-05-27T07:13:56+00:00', 'source': 'data/NeuralNet.pdf', 'total_pages': 8, 'page': 7, 'page_label': '8'}, page_content='4. No of neurons in each layer \\n5. Activation function choice \\nApplications and Scope of Neural Networks: Neural Networks finds application from industry to \\nday-to-day tasks like image recognition, speech to text, machine translation, signature \\nverification, object detection, and many more.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_documents(documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb891457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for each chunk\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Used for:\n",
    "# A. create database\n",
    "# B. query database\n",
    "def get_embedding_function():\n",
    "   return HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e59b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear database\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"chroma\"):\n",
    "    shutil.rmtree(\"chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "def chroma_database(chunks: list[Document]):\n",
    "    # Add non-duplicate chunks to Chroma vector DB\n",
    "    \n",
    "    # Connect to existing Chroma DB or create a new one\n",
    "    db = Chroma(\n",
    "        persist_directory=\"chroma\",\n",
    "        embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Add unique IDs to each chunk\n",
    "    chunk_with_ids = assign_ids(chunks)\n",
    "\n",
    "    # Get existing document IDs from the DB\n",
    "    existing_ids = set(db.get(include=[])[\"ids\"])\n",
    "    print(\"Existing documents in database:\", len(existing_ids))\n",
    "\n",
    "    # Filter only new (non-duplicate) chunks\n",
    "    new_chunks = [\n",
    "        chunk for chunk in chunk_with_ids\n",
    "        if chunk.metadata[\"id\"] not in existing_ids\n",
    "    ]\n",
    "\n",
    "    # Add only new chunks\n",
    "    if new_chunks:\n",
    "        print(\"Adding new documents:\", len(new_chunks))\n",
    "        new_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"No new documents to add.\")\n",
    "\n",
    "def assign_ids(chunks: list[Document]) -> list[Document]:\n",
    " \n",
    "    # Assign a unique ID to each chunk based on:\n",
    "    # file:page_number:chunk_index\n",
    "\n",
    "    last_page = None\n",
    "    chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        src = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        page_id = f\"{src}:{page}\"\n",
    "\n",
    "        if page_id == last_page:\n",
    "            chunk_index += 1\n",
    "        else:\n",
    "            chunk_index = 0\n",
    "\n",
    "        chunk.metadata[\"id\"] = f\"{page_id}:{chunk_index}\"\n",
    "        last_page = page_id\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda4ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8s/mn5fpc71161_x21w08svrtfm0000gn/T/ipykernel_55223/1748374862.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  return HuggingFaceEmbeddings(\n",
      "/Users/anayagarde/Documents/Projects/LLM-RAG/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/8s/mn5fpc71161_x21w08svrtfm0000gn/T/ipykernel_55223/3971298570.py:8: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing documents in database: 0\n",
      "Adding new documents: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8s/mn5fpc71161_x21w08svrtfm0000gn/T/ipykernel_55223/3971298570.py:31: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "chroma_database(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53dc3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load a local language model\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "def query_rag(query_text):\n",
    "    # Load the embedding function (e.g., HuggingFaceEmbeddings)\n",
    "    embedding_function = get_embedding_function()\n",
    "\n",
    "    # Load vector store\n",
    "    db = Chroma(\n",
    "        persist_directory=\"chroma\",\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    # Retrieve top-k most relevant documents\n",
    "    result = db.similarity_search_with_score(query_text, k=5)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in result])\n",
    "\n",
    "    # Format prompt\n",
    "    prompt = f\"Answer the question based on the context.\\nContext: {context_text}\\n\\nQuestion: {query_text}\"\n",
    "\n",
    "    # Generate response using Hugging Face pipeline\n",
    "    response = generator(prompt, max_new_tokens=256)[0][\"generated_text\"]\n",
    "\n",
    "    # Format and print the response\n",
    "    formatted_response = f\"Question:\\n{query_text}\\n\\nResponse:\\n{response.strip()}\"\n",
    "    print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e2f165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What are the documents about?\n",
      "\n",
      "Response:\n",
      "In the world of AI, Machine Learning, Deep Learning, and Computer Vision, we have come across and heard about various tasks like Image Classification, Object Detection, Image Pattern Detection, Text Classification, and Face Recognition. In this article, I have written a quick overview of Convolutional Neural Networks.\n"
     ]
    }
   ],
   "source": [
    "query_rag(\"What are the documents about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f489308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Explain COnvoluational Neural Networks\n",
      "\n",
      "Response:\n",
      "The relevant information is: Convolutional Neural Network (CNN or ConvNets) is a Deep Learning technique which is generally used to perform the tasks mentioned above. Here, the input is an image (simply a matrix of pixels) which is fed into a CNN model that assigns some learnable weights and biases to various aspects of an image to analyze input images for recognition and classification. Here, the input is an image (simply a matrix of pixels) which is fed into a CNN model that assigns some learnable weights and biases to various aspects of an image to analyze input images for recognition and classification. Here, the input is an image (simply a matrix of pixels) which is fed into a CNN model that assigns some learnable weights and biases to various aspects of an image to analyze input images for recognition and classification. Here, the input is an image (simply a matrix of pixels) which is fed into a CNN model that assigns some learnable weights and biases to various aspects of an image to analyze input images for recognition and classification. Here, the input is an image (simply a matrix of pixels\n"
     ]
    }
   ],
   "source": [
    "query_rag(\"Explain COnvoluational Neural Networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b4ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
